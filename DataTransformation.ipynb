{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20e69d57-5bce-40ec-a9a6-4160b1bda57d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "SILVER LAYER SCRIPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "648085dc-e3de-4bb3-b3a2-86c9655f4f02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "patient data transformation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fa37e1b-040e-4093-a3af-378db9f1d6a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "bronze_pt_df = spark.table(\"bronze_fhir_patient\")\n",
    "# Start from flattened data\n",
    "silver_df = (\n",
    "    bronze_pt_df\n",
    "    .withColumn(\"name_given\", expr(\"name[0].given[0]\"))\n",
    "    .withColumn(\"name_family\", expr(\"name[0].family\"))\n",
    "    .withColumn(\"identifier_system\", expr(\"identifier[0].system\"))\n",
    "    .withColumn(\"identifier_value\", expr(\"identifier[0].value\"))\n",
    "    .withColumn(\"address_city\", expr(\"address[0].city\"))\n",
    "    .withColumn(\"address_postalCode\", expr(\"address[0].postalCode\"))\n",
    "    .withColumn(\"telecom_system\", expr(\"telecom[0].system\"))\n",
    "    .withColumn(\"telecom_value\", expr(\"telecom[0].value\"))\n",
    "    .withColumn(\"dq_flag\", expr(\"\"\"\n",
    "        CASE \n",
    "            WHEN id IS NULL THEN 'FAIL'\n",
    "            WHEN gender NOT IN ('male', 'female', 'other', 'unknown') THEN 'FAIL'\n",
    "            WHEN birthDate IS NULL THEN 'FAIL'\n",
    "            ELSE 'PASS'\n",
    "        END\n",
    "    \"\"\"))\n",
    ")\n",
    "\n",
    "# Separate good vs bad\n",
    "dq_pass = silver_df.filter(col(\"dq_flag\") == \"PASS\")\n",
    "dq_fail = silver_df.filter(col(\"dq_flag\") == \"FAIL\")\n",
    "\n",
    "# Write valid data\n",
    "dq_pass.select(\n",
    "    \"id\", \"gender\", \"birthDate\", \"name_given\", \"name_family\",\n",
    "    \"identifier_system\", \"identifier_value\", \"address_city\",\n",
    "    \"address_postalCode\", \"telecom_system\", \"telecom_value\",\n",
    "    \"_source_file\", \"_ingest_time\"\n",
    ").write.format(\"delta\").mode(\"append\").saveAsTable(\"silver_fhir_patient\")\n",
    "\n",
    "# Optionally, store invalid records separately\n",
    "dq_fail.write.format(\"delta\").mode(\"append\").saveAsTable(\"dq_errors_fhir_patient\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "846c3d9e-41d2-47ab-ad41-1395138137f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "observation data transformation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8ec1433-d93c-4a20-a361-2f0d95f71585",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "bronze_obs_df = spark.table(\"bronze_fhir_observation\")\n",
    "\n",
    "silver_obs_df = (\n",
    "    bronze_obs_df\n",
    "    .withColumn(\"code_system\", expr(\"code.coding[0].system\"))\n",
    "    .withColumn(\"code_code\", expr(\"code.coding[0].code\"))\n",
    "    .withColumn(\"code_display\", expr(\"code.coding[0].display\"))\n",
    "    .withColumn(\"code_text\", col(\"code.text\"))\n",
    "    .withColumn(\"subject_reference\", col(\"subject.reference\"))\n",
    "    .withColumn(\"value_quantity_value\", expr(\"component[0].valueQuantity.value\"))\n",
    "    .withColumn(\"value_quantity_unit\", expr(\"component[0].valueQuantity.unit\"))\n",
    "    .withColumn(\n",
    "        \"dq_flag\",\n",
    "        expr(\"\"\"\n",
    "            CASE\n",
    "                WHEN id IS NULL THEN 'FAIL'\n",
    "                WHEN status IS NULL THEN 'FAIL'\n",
    "                WHEN code_code IS NULL THEN 'FAIL'\n",
    "                WHEN subject_reference IS NULL THEN 'FAIL'\n",
    "                WHEN effectiveDateTime IS NULL THEN 'FAIL'\n",
    "                ELSE 'PASS'\n",
    "            END\n",
    "        \"\"\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Split PASS and FAIL records\n",
    "dq_pass_obs_df = silver_obs_df.filter(col(\"dq_flag\") == \"PASS\").drop(\"dq_flag\")\n",
    "dq_fail_obs_df = silver_obs_df.filter(col(\"dq_flag\") == \"FAIL\")\n",
    "\n",
    "# Write PASS records to Silver table\n",
    "dq_pass_obs_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"silver_fhir_observation\")\n",
    "\n",
    "# Write FAIL records to a separate DQ error table\n",
    "dq_fail_obs_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"dq_errors_fhir_observation\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DataTransformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
