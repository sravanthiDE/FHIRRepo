{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f2e7e3e-87d6-45ef-8c60-98e560439067",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "GOLD LAYER SCRIPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5dc3e9f-a6b6-46c0-9835-73839831cfce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "patient data load script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f3bb4ef-6bc4-44cb-98f2-869557b1d155",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import datetime\n",
    "\n",
    "load_ts = datetime.now().isoformat()\n",
    "\n",
    "# Read from silver and add load timestamp\n",
    "silver_patient = (\n",
    "    spark.table(\"silver_fhir_patient\")\n",
    "    .withColumn(\"load_timestamp\", F.lit(load_ts))\n",
    ")\n",
    "\n",
    "try:\n",
    "    dim_patient = DeltaTable.forName(spark, \"gold_dim_patient\")\n",
    "    dim_patient_df = dim_patient.toDF()\n",
    "except:\n",
    "    dim_patient_df = None\n",
    "\n",
    "if dim_patient_df:\n",
    "    # Join current records for comparison\n",
    "    joined = (\n",
    "        silver_patient.alias(\"s\")\n",
    "        .join(\n",
    "            dim_patient_df.filter(\"current_flag = true\").alias(\"d\"),\n",
    "            F.col(\"s.id\") == F.col(\"d.patient_id\"),\n",
    "            \"left\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Identify new or changed records\n",
    "    changes = joined.filter(\n",
    "        F.col(\"d.patient_id\").isNull() |\n",
    "        (F.col(\"s.gender\") != F.col(\"d.gender\")) |\n",
    "        (F.col(\"s.birthDate\") != F.col(\"d.birthDate\"))\n",
    "    ).select(\"s.*\")\n",
    "else:\n",
    "    changes = silver_patient\n",
    "\n",
    "# Proceed only if changes exist\n",
    "if changes.count() > 0:\n",
    "    if dim_patient_df:\n",
    "        # Close out existing active records\n",
    "        closing = (\n",
    "            dim_patient_df.filter(\"current_flag = true\")\n",
    "            .join(changes, dim_patient_df.patient_id == changes.id)\n",
    "            .withColumn(\"effective_end_date\", F.lit(load_ts))\n",
    "            .withColumn(\"current_flag\", F.lit(False))\n",
    "        )\n",
    "\n",
    "        # New SCD2 inserts with new surrogate key\n",
    "        new_rows = (\n",
    "            changes\n",
    "            .withColumnRenamed(\"id\", \"patient_id\")\n",
    "            .withColumn(\"patient_sk\", F.monotonically_increasing_id())\n",
    "            .withColumn(\"effective_start_date\", F.lit(load_ts))\n",
    "            .withColumn(\"effective_end_date\", F.lit(None).cast(\"string\"))\n",
    "            .withColumn(\"current_flag\", F.lit(True))\n",
    "        )\n",
    "\n",
    "        # Final dataframe for overwrite\n",
    "        final_df = (\n",
    "            dim_patient_df\n",
    "            .unionByName(closing.select(dim_patient_df.columns), allowMissingColumns=True)\n",
    "            .unionByName(new_rows.select(dim_patient_df.columns), allowMissingColumns=True)\n",
    "        )\n",
    "    else:\n",
    "        # First-time load\n",
    "        final_df = (\n",
    "            changes\n",
    "            .withColumnRenamed(\"id\", \"patient_id\")\n",
    "            .withColumn(\"patient_sk\", F.monotonically_increasing_id())\n",
    "            .withColumn(\"effective_start_date\", F.lit(load_ts))\n",
    "            .withColumn(\"effective_end_date\", F.lit(None).cast(\"string\"))\n",
    "            .withColumn(\"current_flag\", F.lit(True))\n",
    "        )\n",
    "\n",
    "    # Overwrite gold_dim_patient with new version\n",
    "    final_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold_dim_patient\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73938eb0-88b9-4d81-b907-8336554cecef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "observation data loading script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85ca0b38-645f-425c-bf15-c5eb96ab3335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import datetime\n",
    "\n",
    "# Set the load timestamp\n",
    "load_ts = datetime.now().isoformat()\n",
    "\n",
    "# Read Silver Layer Observation table\n",
    "silver_obs = (\n",
    "    spark.table(\"silver_fhir_observation\")\n",
    "    .withColumn(\"load_timestamp\", F.lit(load_ts))\n",
    ")\n",
    "\n",
    "# Read Dimension Patient table (only active rows)\n",
    "dim_patient_active = (\n",
    "    spark.table(\"gold_dim_patient\")\n",
    "    .filter(F.col(\"current_flag\") == True)\n",
    "    .select(\"patient_id\", \"patient_sk\")\n",
    ")\n",
    "\n",
    "# Join observations to dimension patients\n",
    "fact_obs = (\n",
    "    silver_obs.alias(\"obs\")\n",
    "    .join(\n",
    "        dim_patient_active.alias(\"dim\"),\n",
    "        F.col(\"obs.subject_reference\") == F.col(\"dim.patient_id\"),\n",
    "        \"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Extract useful nested fields from arrays\n",
    "fact_obs_enriched = (\n",
    "    fact_obs\n",
    "    .withColumn(\"category_code\", F.expr(\"category[0].coding[0].code\"))\n",
    "    .withColumn(\"category_display\", F.expr(\"category[0].coding[0].display\"))\n",
    "    .withColumn(\"category_system\", F.expr(\"category[0].coding[0].system\"))\n",
    "    .withColumn(\"interpretation_code\", F.expr(\"interpretation[0].coding[0].code\"))\n",
    "    .withColumn(\"interpretation_display\", F.expr(\"interpretation[0].coding[0].display\"))\n",
    "    .withColumn(\"interpretation_system\", F.expr(\"interpretation[0].coding[0].system\"))\n",
    "    .withColumn(\"performer_reference\", F.expr(\"performer[0].reference\"))\n",
    "    .withColumn(\"meta_profile\", F.expr(\"meta.profile[0]\"))\n",
    "    .withColumnRenamed(\"id\", \"observation_id\")\n",
    ")\n",
    "\n",
    "# Define allowed statuses for validation\n",
    "allowed_statuses = [\"final\", \"registered\", \"preliminary\"]\n",
    "\n",
    "# Apply Data Quality Checks\n",
    "fact_obs_dq = (\n",
    "    fact_obs_enriched\n",
    "    .filter(F.col(\"observation_id\").isNotNull())\n",
    "    .filter(F.col(\"patient_sk\").isNotNull())\n",
    "    .filter(F.col(\"status\").isin(allowed_statuses))\n",
    "    .withColumn(\"effectiveDateTime_parsed\", F.to_timestamp(\"effectiveDateTime\"))\n",
    "    .filter(F.col(\"effectiveDateTime_parsed\").isNotNull())\n",
    "    .filter(F.col(\"code_code\").isNotNull() & F.col(\"code_system\").isNotNull())\n",
    "    .filter(\n",
    "        F.col(\"value_quantity_value\").isNull() | (F.col(\"value_quantity_value\") >= 0)\n",
    "    )\n",
    "    .dropDuplicates([\"observation_id\"])\n",
    "    .withColumn(\"fact_observation_sk\", F.monotonically_increasing_id())\n",
    ")\n",
    "\n",
    "# Select final columns for the fact table\n",
    "fact_obs_final = (\n",
    "    fact_obs_dq\n",
    "    .select(\n",
    "        \"fact_observation_sk\",\n",
    "        \"observation_id\",\n",
    "        \"patient_sk\",\n",
    "        \"status\",\n",
    "        \"code_code\",\n",
    "        \"code_display\",\n",
    "        \"code_system\",\n",
    "        \"category_code\",\n",
    "        \"category_display\",\n",
    "        \"category_system\",\n",
    "        \"effectiveDateTime\",\n",
    "        \"performer_reference\",\n",
    "        \"interpretation_code\",\n",
    "        \"interpretation_display\",\n",
    "        \"interpretation_system\",\n",
    "        \"value_quantity_value\",\n",
    "        \"value_quantity_unit\",\n",
    "        \"resourceType\",\n",
    "        \"load_timestamp\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Perform Delta MERGE to avoid duplicates\n",
    "try:\n",
    "    # Check if the table exists\n",
    "    delta_table = DeltaTable.forName(spark, \"gold_fact_observation\")\n",
    "\n",
    "    # Perform Merge\n",
    "    delta_table.alias(\"tgt\").merge(\n",
    "        fact_obs_final.alias(\"src\"),\n",
    "        \"tgt.observation_id = src.observation_id\"\n",
    "    ).whenNotMatchedInsertAll().execute()\n",
    "\n",
    "except:\n",
    "    # Table does not exist, so create it\n",
    "    fact_obs_final.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold_fact_observation\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Dataloading",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
